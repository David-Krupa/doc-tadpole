<img align="right" src="https://github.com/braingu/tadpole/blob/master/images/TLP/TLPAmber.png">


### An interview with Michael Kahn

[https://www.vice.com/en_us/article/v7gd9b/facebook-helped-fbi-hack-child-predator-buster-hernandez](https://www.vice.com/en_us/article/v7gd9b/facebook-helped-fbi-hack-child-predator-buster-hernandez)

> “The precedent of a private company buying a zero-day to go after a criminal,” said a source who had knowledge of the investigation and development of the exploit. “That entire concept is fucked up [...] it’s sketchy as hell.”

While this particular hack was intended to be used against a specific, heinous criminal, handing zero-day exploits to law enforcement comes with the risk that it will be used in other, less serious cases. The security of these products can't be compromised for some without compromising all, and so zero-day hacking tools are often [closely-held secrets and sold for high sums](https://www.vice.com/en_us/article/8xdayg/iphone-zero-days-inside-azimuth-security). If they got into the wrong hands, it could be disastrous.

Why is Facebook doing this? The government is perfectly capable of buying its own exploits. If you take Facebook out of the equation, there’s nothing new here, nothing out of the ordinary. Microsoft does a ton of security enforcements that borders on a nation-state like taking down domains and coordinated actions with the government. There are certainly private companies that get closer to that boundary of acting as a nation-state in a law enforcement/community protection angle. But that’s still really different than paying an exploit developer. Was this just Stamos deciding he was done with this, and doing it?

Certainly, private companies developing their own exploit shops is not a positive thing. They have even less accountability than elected governments do. And their duty is not to the public — shareholders or investors. But even companies that try to have a broader view of their impact are not going to be as responsible to the public and an individual country’s framework as the country is.

If we found out that Facebook was funding a private army, we would be concerned about that because it is a non-state entity. We hope that a state has a monopoly on force, and companies getting into that without accountability to institutions is not a great development.

Pulling the Facebook piece away, he’s mostly ok with the rest of the approach. The FBI tried to hack, failed, and Facebook helped them out. The vulnerability they found was already being patched. Specific case, time limited, and lower impact.

The fact that they didn’t disclose to the developer after they used it is more questionable.

Five years ago, he had more confidence that the government wouldn’t move against its own people. If he could be reasonably confident that there were controls in place… it’s something he’s very borderline on. He wouldn’t want to do it — he’d want to know as many details as he could. In this specific case he’d be fine with it.

If the crime changed (arms dealer) would he be OK with it? He doesn't think that the techniques themselves are better or worse depending on what crime they are being used to solve. If it's on the shelf it will be used. He’d want specific policies and enforcement around usage… he’d have trouble justifying it right now in the environment that they’re in. Normally there’s some reassurance that if you require things to be signed off by enough people that you provide some protection from abuse. You can't just have some frontline cop who decides to abuse the tool for their purpose. The idea that authority and responsibility and having multiple levels of authority protects against abuse is not as convincing as it once was. Also, remember all of the reports about [FISA](https://en.wikipedia.org/wiki/Foreign_Intelligence_Surveillance_Act) and how the FBI didn’t follow their own policies.
