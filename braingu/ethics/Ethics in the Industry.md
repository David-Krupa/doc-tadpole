<img align="right" src="https://github.com/braingu/tadpole/blob/master/images/TLP/TLPAmber.png">

### An Interview with Michael Kahn

## Contents

- [The Confessions of Marcus Hutchins, the Hacker Who Saved the Internet](#-the-confessions-of-the-hacker-who-saved-the-internet)
- [Exclusive: Ex-NSA cyberspies reveal how they helped hack foes of UAE](#exclusive-ex-nsa-cyberspies-reveal-how-they-helped-hack-foes-of-uae)
- [Security or Surveillance?](#-security-or-surveillance)
- [Privacy and safety](#privacy-and-safety)
- [Does technology substantively change the already extant rules of ethics in espionage?](#does-technology-substantively-change-the-already-extant-rules-of-ethics-in-espionage)
- [As an independent contractor yet citizen, do you take your lead on ethics from the standards established by the nation-state you reside under, or do you evolve personal ethical guardrails?](#as-an-independent-contractor-yet-citizen-do-you-take-your-lead-on-ethics-from-the-standards-established-by-the-nation-state-you-reside-under-or-do-you-evolve-personal-ethical-guardrails)
- [How often are those ethical guardrails a topic of discussion amongst your peers?](#how-often-are-those-ethical-guardrails-a-topic-of-discussion-amongst-your-peers)
- [Discuss the term “mercenary”](#discuss-the-term-mercenary)
- [What role mentorship?](#what-role-mentorship)


## [The Confessions of Marcus Hutchins, the Hacker Who Saved the Internet](https://www.wired.com/story/confessions-marcus-hutchins-hacker-who-saved-the-internet/)

One really good thing about working at BrainGu is having the ability to influence their customers, who think they have an idea but don’t really understand the larger context. If we can bring them a perspective that has more of this thought out and avoid some of the pitfalls they might fall into if they just tried to go for it like everything was new, or working with a company who cares less about it… There are reasons to take on some work that has consequences, if we think we can do so in a way that doesn’t violate our own values. It’s a dangerous self-justification. The danger there is, you have to be able to question your involvement in something like that as often as you need to, and he thinks that having the ability as a person as the context around you changes, is really hard. Doing it as an organization has advantages and disadvantages. People not in the tank have less subjectivity.

On the other hand, organizational inertia is a thing and it’s hard to say that ‘we’re giving up this sure thing that pays us money because we don't like the interaction”

He has mixed feelings about formal corporate values. If you know the organization has values, it makes you more able to say something, knowing you won’t be fired because you reported legitimate misconduct. Aside from whistleblowers and all that, knowing that the company has your back if you see something going the wrong way makes a big difference.

The line can be blurry. Probably a lot more blurry in hacking than in arms cases. The distinction between creating and using an exploit is a much smaller step than building a gun and using it. It’s likely to be the same group of people. NSO group was in the news recently. They build spy software, but also there's some evidence they’re consulting on its use as well as selling and running operations.


## [Exclusive: Ex-NSA cyberspies reveal how they helped hack foes of UAE](https://www.reuters.com/investigates/special-report/usa-spying-raven/)

This is a really well-written article. There are a lot of things around kinda shady companies that did shady things. It’s more interesting because it’s about former NSA people doing compromising things in action. Then everything fell apart. A lot of different people came up with different conclusions. Some people thought that it was legal so it’s fine, while others were in disbelief. People saw things were going bad and got out. Not as clear cut as to where it went bad.

Ego/pride certainly enters into the moral calculus. It can go both ways. In one sense, you can think that you’re only going to work on things you were selective about. But there’s also the flipside of, an attitude of “I want to work on the hardest and most interesting problems and do the coolest stuff I can find because i”m the best at it.”

There’s a greater responsibility if you’re making the choice between creating the tool and using the tool. In most cases, it isn’t a very large distinction. If you know what you’re building and what it’s for, the fact that you aren’t pushing the button isn’t that big an impact. If you build something that you don’t actually know what it will be used for but it could be used for something malicious… some people are cool with writing code for missiles without launching them. If you consider yourself part of a team, it can be harder to be the one who says “let’s not do this”. You don’t want to disappoint the team. Whereas lone wolf super hacker, the only person you’re impacting is the person you’re working for and your reputation, so there’s less peer pressure.

## [Security or Surveillance?](https://www.lawfareblog.com/security-or-surveillance)

It’s a myopic framing that focuses only on one threat — criminals, including domestic terrorists — and the demands of law enforcement and national intelligence. This obscures the most important aspects of the encryption issue: the security it provides against a much wider variety of threats.

Compare this with the tactic of secretly poisoning all the food at a restaurant. Yes, we might get lucky and poison a terrorist before he strikes, but we’ll harm all the innocent customers in the process. Weakening encryption for everyone is harmful in exactly the same way. He's not sure why he broke it up between legal hacking and going dark. More like breaking tools apart from “going dark”, specifically the US government side around it.

For BrainGu, he wasn’t as interested in those details, because we’re only working for the US government. The UK side is probably the same conversation. There's a lot of common discussions there. The question about Germany would be interesting.

He’s not convinced that the argument is as clear cut as either side wants it to be. He agrees that weakening encryption is a bad idea, as has been stated lots of times. One option is to say “we won’t make these compromises; let's stop trying and focus law enforcement elsewhere.” The back and forth argument between law enforcement and privacy is one that is important to keep having; hopefully along the way there’s a new realization that can accept that there are different options and ways to deal with that produce the most good with the least harm.

Largely because of the “Going Dark” thing, it seems like going after encryption is the first, rather than last, resort, from people in a position of policy. Maybe interview witnesses first? From attorneys general, they’re looking for an excuse to have the encryption fight, which seems like it’s a dangerous approach. OTOH, constantly questioning received knowledge is worth doing. Just because a group of people strongly say that we can never weaken encryption, and we should never look at ways to allow a backdoor, that doesn't mean that by itself it’s not worth examining that argument. There's a lot of logic and evidence behind the argument that there is no good way to break encryption without compromising everyone.

A paper came out a year or so ago where researchers tried to examine the issue and propose a couple new ideas for how to have government access within encrypted systems, trying to find a compromise between the two; sacrosanct or backdoor. Seems like it got mixed feedback.

## Privacy and safety

- [Lawful Hacking: Using Existing Vulnerabilities for Wiretapping on the Internet](http://scholarlycommons.law.northwestern.edu/cgi/viewcontent.cgi?article=1209)

- [Lawful Hacking and the Case for a Strategic Approach to “Going Dark”](https://www.lawfareblog.com/lawful-hacking-and-case-strategic-approach-going-dark)
> “But the government must be clear that the American people expect law enforcement to prevent, investigate, and prosecute crimes.”

- [We Could Not Look the Survivors in the Eye if We Did Not Follow this Lead](https://www.lawfareblog.com/we-could-not-look-survivors-eye-if-we-did-not-follow-lead)
Although this case is about the innocents attacked in San Bernardino, it does highlight that we have awesome new technology that creates a serious tension between two values we all treasure: privacy and safety. That tension should not be resolved by corporations that sell stuff for a living. That’s false equivalence, appeal to authority, emotional appeal, emotional manipulation.

There are plenty of well-supported arguments on the pro-encryption side. There are also a lot of knee-jerk reactions, partly due to well-proven experience, not wanting to re-engage with the same arguments for the last 30 years. The government doesn’t appreciate the positive outcomes. The good arguments are there, but there are also a fair amount of “we’re done having this conversation” conversations.



## Does technology substantively change the already extant rules of ethics in espionage?

It doesn’t necessarily change the rules, per se. It very much changes how the rules are implemented and what the practical applications are. The principles aren’t dramatically different, but there's a lot more capacity for effects than before.

It’s tough with the legislators needing to understand what they’re legislating. Especially when very few of the people interested in making these decisions understand what’s going on. And Congress removed their science advisors.


## As an independent contractor yet citizen, do you take your lead on ethics from the standards established by the nation-state you reside under, or do you evolve personal ethical guardrails?

The latter, but clearly, the latter is hugely informed by the environment that education, laws, and societal ethics have in common with the standards established by his nation-state. Even if those are in conflict, there’s still a lot of weight drawn from the idea that a representative government should carry weight with the people they’re representing.

Note bene: illegal is not necessarily unethical.

## How often are those ethical guardrails a topic of discussion amongst your peers?

Some discussions at BrainGu. Not frequently. He’s had more discussions about the higher level, about how should BrainGu handle ethical questions, than talking in a lot of detail about implications of things.

## Discuss the term “mercenary”

It’s an interesting analogy, because… there’s a mercenary analogy but also arms dealer analogy. If you’re one of the companies that builds and sells exploits, it’s pretty much equivalent to being an arms dealer. There are a larger variety of applications that don’t directly involve use of force. More or less, though, it’s a niche. The mercenary side is more the direct involvement/direct action. In certain cases, the state reserves authority to itself; only state actors can use force or run cyber ops. Or, they delegate to proxies and have different levels of control of those proxies. The US has tight control, China delegates but has control of who they delegate to. Iran and North Korea give control to individuals and lets them run wild.

## What role mentorship?

Certainly as someone coming in new, you’ll be heavily influenced by who you’re learning from. To some extent that’s luck of the draw and can have really different consequences. It’s important to recognize the influence you’re having, consciously or unconsciously, figuring out how much you should be restrictive, and how much you should let people explore questions on their own. It’s certainly possible to have a corporate policy that outlines every single possible scenario. But if you’re trying to train someone new, they probably have some values they hold themselves that they’re bringing to the conversation.

Which is a stronger pull, peers or role models? If you’re new and don’t have a ton of confidence, it’s likely one of your primary drivers is not letting people down/not embarrassing yourself. Hard to overcome that without having experience.
