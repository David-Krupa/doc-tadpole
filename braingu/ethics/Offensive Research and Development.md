<img align="right" src="https://github.com/braingu/tadpole/blob/master/images/TLP/TLPAmber.png">

### Interview with Michael Kahn

*   Being a researcher (white hat) and reporting what you find to the developer is a different case than making hacking tools.
*   He thinks that a) if you’re doing any of that kind of work and you aren’t staying awake at night trying to figure out if every decision you made that day is the right one, then you’re probably doing it wrong. You're already at a bad place if you aren’t constantly questioning if you’re doing the right thing. And if you are, you come to your own conclusions. Clearly some people who come to their own seem to have gone way off track. Specifically the ones selling to oppressive regimes whose tools are being used to find and torture people. Middle ground between that and just researching in a defensive sense.
*   That’s where most of the interesting questions are. It’s a risky place to be, and it seems like aside from the technical burnout from staring at low-level code forever and trying to figure it out, the burnout from trying to figure out whether you’ve come up to your ethical line, would be exhausting.
*   He doesn't know if it’s true across the industry, but the amount of euphemism or talking around things — probably quite true around government things — it’s hard to even start conversations, because people are afraid to use words that actually describe what’s going on. Not that it’s classified, but like all of the DoD-speak, jargon is a barrier to entry to anyone trying to learn what people are talking about. It’s doubly bad, because DoDisms, and then there's the hacking community, which has even more gatekeeping, and then nobody knows what anyone’s talking about.
*   He thinks there’s some movement between roles (hacker, researcher, etc.). People are drawn to different things, but they aren’t hard and fast. It’s about what they would most rather be doing.


## OffensiveCon Keynote

[https://github.com/braingu/tadpole/blob/master/documents/OffensiveCon%20Keynote.pdf](https://github.com/braingu/tadpole/blob/master/documents/OffensiveCon%20Keynote.pdf)

*   Spence sent it to him, as something he thought he’d be interested in.
*   Does a good job of concisely explaining the different angles and considerations that someone who’s actually in the industry has made. Valuable for someone on the inside.
*   Pointing out that there are only so many choices for if you want to do offensive work. All options have tradeoffs.
*   The piece about how eventually he got tired of thinking every day how much grey area he wanted to deal with.
*   Slide of Not the customers money. Not that different from anything else in the military industrial complex.
*   Studies must exist for how the market for exploits is affected by government purchasing. “There’s always going to be a market for these tools, and if the good guys aren’t buying it, someone will” He’s pretty sure that’s not exactly how a market works. He thinks that that forgets supply/demand. Doesn't know how much actual research there’s been.
*   There are individuals who are remarkably skilled at specific things and have a way of thinking about the problems that they’re trying to solve that allows them to move faster and see stuff no one else sees.
*   “Science and conflict” — that decision may not be yours. There are many situations in which you’re directly helping warfare. But plenty of situations where people who thought they were doing pure science found their ideas elsewhere. You may work on something never used for military applications, but you don't know that when you're working on it.


## Predicting the Consequences

*   Predicting the consequences of whatever you’re doing is extremely difficult. You’re not automatically suspect working on military applications. But you need to be able to live with whatever the consequences of your actions are.
*   Some consequences are easier to see than others. A lot of that is based on where you are between pure academic research vs. the “things that go boom” side. If you’re further out, it’s harder to know the consequences. The necessity of, for social networking things, where it’s your responsibility to think of what the worst possible abuse of the system could be as you’re building it.
*   An important part of the tech lead responsibility is figuring out the consequences. Anybody no matter what level needs to be thinking through what they’re working on and not just following orders. Especially in a tech lead role, you often have the best combined understanding of the tech work your team is doing and the motivations around what it’ll be used for.
*   Hiroshima if you work in Cyberwar. One, it’s the extreme example of if you call what you’re doing “war” ironically, at some point the line between those two will fail, and a bunch of people who thought they were working on cyber war will be working on actual war, and that will be a shock. Recognition of “war has consequences”. Probably also the atomic bomb was particularly scientifically driven and a lot of academics working on it. In 1940, you could say that real mathematics has no effect on war, given a bunch of early modern and enlightenment scientists got their money doing ballistics tables.
*   Death squads. As time goes on it becomes clearer and clearer how the march of progress is not inevitable, nor in one direction. Look up articles on the phrase “democratic backsliding”, especially in Eastern Europe. Also, the popularization of illiberal democracies. Governments that still reflect the will of the electorate, but scrapped the core values (like Poland, and Hungary). “Truth and reconciliation commissions” seems like they have a decent track record, but…
*   He feels like this is something that has more context in the actual talk. His conclusion where he says unusually peaceful time and being conscious of that is important. It biases your thinking if you think you’re willing to do a thing because it’s being used to solve crime rather than war, defense rather tha offence, that making those assumptions doesn’t mean that whoever you sold this thing to won't have a completely different outlook 5-10 years from now. Just because they are good guys now, doesn’t mean that might not possibly change.


## Vulnerability Disclosure

*   Doesn’t have a fully developed model of how he thinks it should work. He thinks that you have to weigh the pros and cons. In his view, the default should be disclosure. You should have to prove a reason why you should hold onto it. This is where the Obama process ended up post-Snowden. Default disclosure.
*   The Facebook one. There was a paragraph at the bottom that said it wasn’t a big deal because of the patch. But even after that they didn’t disclose. Possibly patch was just a messy code cleanup (messy code is often vulnerable code).
