# Adversarial Machine Learning
### *by: Albert Jiang*
### 09/17/2021
### Squad Barrel Roll
**Description:** Machine learning models, especially those powered by deep neural networks, have achieved human-level performance in many tasks, and are seeing more and more deployments to our daily lives. However, in the past few years researchers have found that these models are often vulnerable to certain adversarial attacks, including specially-designed  inputs that fool the models into making the wrong decisions. I will give an overview of the ideas behind these adversarial attacks, as well as some of the defensive strategies that have been developed to make ML models more robust against these attacks.

[![Watch the video]](https://drive.google.com/file/d/1dkj5UUO-CaRMwHWRtbpHW_jlLhpjvw7c/view?usp=sharing)
