<img align="right" src="https://github.com/braingu/tadpole/blob/master/images/TLP/TLPAmber.png">



## Contents
* [Philosophy, Mindset, Techniques](#philosophy-mindset-techniques)
  * [Passive](#passive)
  * [Active](#active)
  * [Approach](#approach)
  * [Analysis](#analysis)
    * [Detection](#detection)
    * [Scanners and Sandboxes](#scanners-and-sandboxes)
    * [Deobfuscation](#deobfuscation)
    * [Reverse Engineering (RE) and Debugging](#reverse-engineering-re-and-debugging)
    * [Memory forensics](#memory-forensics)
    * [Packet analysis](#packet-analysis)
    * [Website analysis](#website-analysis)
* [Best Practices](#best-practices)
  * [Books](#books)
  * [Principles](#principles)
  * [Troubleshooting](#troubleshooting)
  * [Example: The [Twitter Hack](https://www.cnn.com/2020/07/15/tech/twitter-hack-elon-musk-bill-gates/index.html)](#example-the-twitter-hackhttpswwwcnncom20200715techtwitter-hack-elon-musk-bill-gatesindexhtml)


## Philosophy, Mindset, Techniques

When starting with a new file to analyze, “what is this?” is not a good enough question. If you receive a file and ask “What is this and what does it do?” you could answer generically, but more specific questions are better. To help you chunk it into manageable, bite-sized pieces, ask

*   How does it run?
*   How does the binary run?
*   What is it attacking?
*   How is it attacking?

Learn more about the surrounding environment as you’re trying to fix the thing. For example, the best way to fix an engine is to replace a single part. In being given a directing problem, you are forced to learn the environment first and then to solve the problem.


### Passive

Passive analysis is equally about getting the information to protect yourself and your network, and not sending information to other systems.



*   No restrictions on passive — you can do whatever you want to do to the file, pull it apart, with no consequences, no lasting effects, and no adversaries.
*   What’s its target? (Word? Browser? What is it trying to leverage? What is it trying to run on?)
*   Any obfuscation/packed binary, password protected, shell, dropper. Figure out as much info about it prior to run as you can, to put it into an environment where it can be analyzed but not do damage. Actual exploit, native calls, what means of leverage?


### Active

Active analysis means doing analysis while the sample has a chance to impact its environment.


*   Leveraging passive info
*   Run it inside a VM or restricted or localized system.
*   If it makes a call out, mimic that, and fetch the info on that. DNS lookup is passive, because it is not invasive. But whenever you send info out, you risk exposure.
    *   WannaCry was a great example — it was looking for external communication.
*   Find the most suitable, correct, or supported environment to execute; loading a Word doc, for instance. You want it to be as protected as possible, using passive info to mitigate exposure, whether it’s a VM isolation or a new physical hardware setup to make sure it doesn’t affect anything else.
*   Run it without an internet connection — see what it does when it doesn’t have external contact.
*   What is it doing? Why is it considered malware? It may actually just be crappy code, not malware.
    *   More often than not, it’s stupid not evil, or just not malware.
    *   At BrainGu, historically, people were already suspicious of files and interactions. That’s because BrainGu is a Tier 2-3 level, not Tier 1, incident response team. If Tier 1 finds a thing, they submit it to BrainGu to figure it out.
    *   False positives (crash, bad instance of nothing).
    *   False negatives (may not find the suspicious things).
    *   Malware analysis used to be a very resource-constrained, human-intensive process. People submitted thousands of samples a day to the Gu team, who were prepared to handle zip, pdf, office, images, whatever, and then do the 80% solution of what the file was, running it through the system, passive and active, then reporting that back to the submitter. The goal was to let them make the choice to analyze further or not.
*   Once it’s isolated, figure out what it’s doing while not connected, then open it up to be internet enabled, making sure you’re going through VPNs so you don’t show who you are (protect yourself). Make sure the network doesn’t get mingled with attributable traffic. Then follow the rabbit hole of what it’s doing for coms — DNS, IP, does it download a file? What file does it download? If it’s just a dropper file, which executes, then start the process recursively until you hit the end of the files.


### Approach

What kinds of situations change your questions?



*   When things get difficult, or you find yourself saying “wow this sucks” or it is taking too long or is overly complicated, reevaluate the approach.
*   What question am I trying to answer?
*   Who am I answering it for?
*   Who is the audience and what am I trying to solve?
    *   How the information is presented changes with the audience. If they are asked to do a thing and it’s not a huge lift and/or they don’t want to do work yet, don’t go as deep as possible.
    *   Sometimes, just do the elevator pitch. Sometimes it’s too much information.
    *   Severity also changes it. For example, during a pentest where they found a link between different live operations, instead of reporting “hey this happened”, they said “this is what happened, here’s how and why, and how you can avoid it” with solutions.
    *   Disclosure comes with high risks. Provide the customer with actionable change — them implementing it is in their control.
    *   You should always try to recommend a solution if you’re able to.


### Analysis

*   Favorite tools
    *   Minimizing human involvement, maximize automation. Getting the 80% solution and letting the people solve the hard problems.
*   Static analysis
*   Dynamic analysis
*   Dynamic Symbolic Execution (DSE)
*   Stages
    *   Manual Code Reversing
    *   Static Properties Analysis — easier to automate
    *   Interactive Behavior Analysis — harder to automate
    *   Fully-Automated Analysis


#### Detection

Proactive vs reactive



*   We prefer you to be more proactive. Start with a foundation like Structsure, so you start securely. That means that at the production level, we don't have to reevaluate our systems to know they were deployed properly. If you start out knowing that you’re in a good state, everything should be easier — best foot forward for minimal exposure/surface area. If something does happen, the scaffolding was there, because we started that way.
*   Security bolted on isn’t best. How are we securing, how are we controlling info?
*   Localhost redirect handling.


#### Scanners and Sandboxes

How do you know which to use when?



*   Depends a lot on scope and scale of what you’re trying to do, the quantity of samples, and frequency with which you're using them.
*   Sandbox — wraps around virtualization (virtualbox). Does a lot of things for you out of the box, like pushing and pulling files, and is easily extensible.
*   You’re only as good as the environment you’re in. Putting yourself at risk, so having good network management, is a huge thing to be aware of and avoid. Understand the foundations of bare metal systems. Understand paths, hypervisors, VMs, network traffic management.
*   Setting up your environment
    *   Check the documentation ([https://cuckoo.sh/docs/installation/index.html](https://cuckoo.sh/docs/installation/index.html))
        *   Setting up local
        *   Enterprise deployment is not documented very well.
    *   What are we trying to protect?
    *   What are we trying to protect it from (attack surface vs. risk surface)?
    *   Evaluate weak points — figure how to protect those.
    *   If you want to run malware samples, what information on the system does it have access to? If you’re building a brand new system that’s easy, but on a network associated with other things, what’s on the network that it could have access to? How are we mitigating what has access? If the malware spills, how are we ensuring we’re protected?
    *   Network defender is the same but without the “intentionally protecting ourselves” mindset.
    *   With a virus, for example, “how do I make sure I don’t catch it?” then “how do I identify who has it?”
    *   No traffic in or out if you can avoid it. If traffic happens, monitor and track. How frequent, how responsive do you need to be? Can it be delayed?


#### Deobfuscation

*   There is always some thing on a file that tells you what it is, whether that’s the file header, magic number, or whatever. Start going through the list. Run it through a disassembler. Once you figure out what it is and how to interact with it, you can glean more info by watching it step through what it’s interacting with. Packed Binary — (means of compressing and modifying a file which changes it but maintains functionality) UPX packer — it’s really common to get garbage instead of actual strings being used. You can figure out what packer the file is using by looking for common calls, functions, non-obfuscated threads, so you should have a good knowledge of the artifacts of commonly used packers. You can Google for these. Base 64 encoding will always have a 64-b boundary, and ends with = or ==, because that’s how it pads to meet that length. So the end string is = or ==.

![](https://github.com/braingu/tadpole/blob/master/images/encode.png)

For a long time, that would fool antivirus.

Obfuscation doesn’t have to be hard or complex, just different.

You learn how to do this both by finding out tribal knowledge, game experience, and also by talking to other people about it. It’s in a lot of textbooks and curriculum, especially with WebDev stuff. Encoding is used as a standard within the industry. Frameworks will automatically do it behind the scenes, or use different formatters.

Just dive into the different encoding types, and figure it out. ([https://stackoverflow.com/questions/6916805/why-does-a-base64-encoded-string-have-an-sign-at-the-end#6916831](https://stackoverflow.com/questions/6916805/why-does-a-base64-encoded-string-have-an-sign-at-the-end#6916831) for example)


#### Reverse Engineering (RE) and Debugging

*   RE is a class of things — the overarch.
*   It’s also an approach vs. a set of tools.
*   [WinDBG](http://windbg.org/) / [Ollydbg](http://www.ollydbg.de/) / [Immunity Debugger](https://www.immunityinc.com/products/debugger/) change as the program is running. Taking vitals as you go, so you can monitor and change as they’re running live.
*   [Ida Pro](https://www.hex-rays.com/products/ida/) / [Binary Ninja](https://binary.ninja/) / [Ghidra](https://ghidra-sre.org/) / [radare](https://www.radare.org/r/) disassemblers.
*   Reconstitute and recompile into legible languages.
*   Gives you the ability and knowledge of methods and calls. How do I get to a certain path? If I was to send something, how would it interact?
*   How do binaries impact the flow of the program? Looking at the sample allows you to make better assumptions and more precise conclusions.
*   Ransomware encryption — they already have a password. How do they have that? Run it through a disassembler, watch as the password goes, what is it being compared to? When does it back out and not decrypt? Then use that to figure out what the actual key is.


#### Memory forensics

What are you looking for in the snapshot?

*   Understanding what memory is and what it looks like. Virtual vs. physical, kernel space vs. user space.  Memory Analysis for Forensics (Volatility memory analyzer tool)
*   Just because something has memory allocated doesn’t mean it’s being stored in the physical RAM chip.
*   Understanding pagefiles (reference and dereference).
*   Understanding how virtual memory is laid out. How they are used by the process. Just because the process is running doesn’t mean it can access kernelspace or userspace.
*   OS-specific stuff. If you have a process running, how does the OS know, what tables does it use, how does it know what processes are going. Understanding task manager. Use it to verify how many are running, and is there memory allocating for a process not showing up in the task manager? Understanding what resources processes have. Certain tables, function calls, methods, handlers that should always be consistent (especially within the kernel), being able to extract and decode files. If you have a 10M file, you won’t have space in one memory block for that file. Being able to navigate what linked lists are (core memory component).
*   In a class, you can create a core class. Different methods are called. But you can have a class that inherits from the main. Common methods in the “vehicle” class, and different methods overwrite them in the subclasses. A virtual table creates a generic table (updates the reference table rather than duplicating code. Common functionality points back to a single reference point.)
*   Look for a “read between the lines” mindset. Just because you allocate 4 but you use 2, if there’s info there that didn’t get zeroed out, you can use that to get more intel for what you’re looking at.
*   Even though someone has closed a Word doc, you can still scrape memory and pull that data from the text.
*   How are you proceeding through it?
*   [Art of Memory Forensics](https://www.amazon.com/Art-Memory-Forensics-Detecting-Malware/dp/1118825098)


#### Packet analysis

What are you looking for first, second, after?

*   Incident response team gives you a capture, start there.
*   If you know suspicious IPs, start there.
*   If you don’t know that, look at what valid resources are on the network, like domain stuff you can use to filter out known good, which helps weed out unnecessary stuff. Doesn’t always help. Can give you false negatives, but shouldn’t give you false positives.
*   Isolating traffic — look to see if there are files you can pull from the traffic (uploads and downloads, web browser traffic, history), finding out if you can get session keys to decrypt session information.

Where does this rate in terms of usefulness and things you do?

*   We’d incorporate this into the proactive approach. The IR team would do this stuff first, and they’d do malware analysis and network analysis using [Wireshark](https://www.wireshark.org/), etc.


#### Website analysis



*   [https://portswigger.net/burp](https://portswigger.net/burp)
    *   Intercept, fuzzing, analyze what’s happening between browser and server.
*   [https://www.amazon.com/Web-Application-Hackers-Handbook-Exploiting/dp/1118026470](https://www.amazon.com/Web-Application-Hackers-Handbook-Exploiting/dp/1118026470)	(in library)
*   Malware
*   Fingerprinting
    *   Cookies
    *   What’s hosting the website
    *   Any exposed or open ports (use portscanner). Shared hosting, other services offered
    *   Certificate issuance — validated by, expiration date, multiple services or names (info that can’t be hidden effectively). Keeps honest people honest. Table of contents for what you should index. Robot.txt.
    *   You can useful info from error pages (404 for example) may give you insight as well (insight developed from reading [Offensive Security: Infosec Training and Penetration Testing](https://www.offensive-security.com/), and then doing other trainings. This book has some of the best on-your-own training “Try Harder”.) They give you a full environment to log into to get going, or they give you the hints to learn the thing.


## Best Practices

*   Being able to solve a problem once and not having to do it again. Should be repeatable and leverageable elsewhere. So if you wrote some code or did some research, make it so it can be easily ported and adapted for other people to use. You never know who might be able to make use of it.
*   [Engineering space](https://braingu.atlassian.net/wiki/spaces/ENG/overview) in the wiki.
*   Most work hasn’t been owned by BrainGu, so they couldn’t keep that stuff, but the processes and knowledge that came from it have been shared. STOR was the bedrock and foundation for Structsure.
*   Easy thing is sharing the resources, not the specific fix. And that’s the best way for people to learn anyway. Rather than being told to set a setting, figure out why to set the setting.
*   Sharing the resources forces understanding and comprehension.
*   Build these off the wiki
    *   Create a template: here’s the problem, here are the resources, here’s how I stepped through it.
    *   “Common sense” gets glossed over; need to adjust for the audience, and what someone coming in would need.


### Books

[https://drive.google.com/drive/u/1/folders/1Wd9m-H-HHeXFNN8Mw1SYQwJO6hEf0xTo](https://drive.google.com/drive/u/1/folders/1Wd9m-H-HHeXFNN8Mw1SYQwJO6hEf0xTo)


### Principles

*   Don’t go too deep into the rabbit hole (Learning too much, or going too much into the wrong area to solve the problem.) Say for example you’re doing malware binary analysis. You look at the wrong call, it ends up being library code. If, for example, you call `printf`, being able to identify those at a high level is a key skill. Not going down rabbit holes of irrelevant info is the biggest thing. As much as you want to understand as much as you can about a thing, learn just as much as you need to go to work, but not too much.
*   Differentiate between rabbit holes, and not. Look at the amount of time you’re spending on the project, or looking back at the problem statement or answer you were reaching for first. If it’s not directly related, then you’re in a rabbit hole.
*   Don’t be afraid to ask, and don’t be afraid to admit you don’t know stuff. Being able to power through on your own is great, but if you can ask someone, they can give you the shortcut and you don’t have to struggle, and point you to the answer and understanding it.
*   This is about exposure and experience. You have to develop your own understanding of how things work. You just have to exercise it, like muscles.
*   Especially with malware, you’re looking at new technology all the time. Malware is more reactive, and if people aren’t writing new malware, you’re not getting new progressions. You have to react to what the bad guys are doing, and learning and figuring out their new techniques… it’s intentionally reactive. You can’t create something.


### Troubleshooting

Something’s broken. What’s the first thing you look at? Then the next?

*   Be lucky. =)
*   If you’re troubleshooting, you know something’s wrong or broken. So figure out what your surfaces are, how it interacts, how you interact with it.
*   So let’s say, you’re building a web page. Understand how they're created and how the user is interacting, then build a bigger picture from all the smaller pieces.
*   Always pick the easiest, smallest stuff first. Start with the lowest level of effort to fix the problem, only fix one thing at a time, only incrementally (because if you try two at a time, you don’t know which fix was the right one.)  Usually the answer is right in front of you. Once you start with the easy things, you get the knowledge base and comfort levels to get to the more complex things.
*   Building from the ground up is the best way to do it; it gives you a deeper appreciation.
*   There’s a certain level of entry people should have to use things. What the thing is, and how it works. You may not have to do a deep dive and understand all the tech, but understanding basic networks, machines, etc, is enough.
*   Making things easier is not always better.
*   What mistakes do you see people make in the troubleshooting process?
    *   Making assumptions that they know how stuff works. They’ll think it can only work one way, and that’s usually false, and limits you based on your understanding. Assumptions aren’t great; verify that it’s doing what you think it’s doing.
    *   Anything is possible. If you say something can’t be done, you’re wrong. When you say that “it can’t do that”, then you are automatically filtering out info that is useful. You’re still limiting yourself and your understanding. (puzzle pieces are all from the same die… different colors would both fit because they have the same cut.)
    *   Don’t assume that you’re wrong or that your assumptions are incorrect. Don’t assume that it’s your fault that something broke. You shouldn’t be able to do it wrong in the right scenarios. For a good UI, or a good program or deliverable, good error handling should be integral. Even bad data put in, should self correct or not have adverse effects. This helps the person understand what the wrong inputs are, rather than making you wonder. A lot of people say “it crashed because I gave it wrong info so I have to change my approach.” Good design should catch bad input and sanitize it, helping the user to learn it correctly.


*   Ways to look at this:
    *   Troubleshooting the thing that’s likely compromised.

    *   Troubleshooting the analysis process itself.

    *   Troubleshooting (or maybe just reverse engineering?) why the malware was findable.

They (the BrainGu team) may not be the ones monitoring things, but they’re collecting that info. They have to aggregate the logs and stuff that the T1 team would be collecting.




*   For example, when you take your car to the mechanic, if you know enough to direct them, that helps. We don’t need to understand everything, just get it to the mechanic.
*   Structsure is already setting up all the proxies, etc. But also all the log aggregation, network monitoring, triage. “We’re automating your network engineers.”
*   80% solution is networking stuff. Every project BrainGu has had, they had to do their own network from scratch. And that’s a couple of weeks, minimum, for standup and testing. Now, with Structsure, it takes 30 minutes. The perk of Structsure is not the app store, but it’s all the backend stuff (authentication, users, etc. The lift people forget about.) We automate it because it can be automated, which reduces time and burden on engineers.


### Example: The [Twitter Hack](https://www.cnn.com/2020/07/15/tech/twitter-hack-elon-musk-bill-gates/index.html)


*   Impressed with the Twitter hack. Disappointed that Twitter had the capability baked in. Would love to know more about the social engineering that happened. Those people shouldn’t have fallen for it.
*   Interesting questions… how long had they been planning on this? How much organization and effort and planning was involved? They obviously picked these three people — but it wouldn’t have been just these three — why did they pick these? When did they start targeting them? Was there any hint or uneasiness prior to that? Did those people have any indication prior? Did they report anything about it? “John from IT…”...   but how much deeper did that go? How far into it did they go? Did they have someone on the inside?
*   The end all is, all those tweets happened at the same time, so they had to have code that did that. Credentials stored. Handcrafted and well-performed attack. Something to admire. But there’s a lot there and it’d be really interesting to see the whole end to end.
*   There’s a whole novel worth of stuff that happened before the main hack.
